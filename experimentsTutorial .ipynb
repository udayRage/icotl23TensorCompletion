{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03d70b5e-5d64-4ab9-becb-3cc500eac4cc",
   "metadata": {},
   "source": [
    "### Step 1 : Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69925270-7439-46d3-b605-080c48d6c540",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import traceback\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from osgeo import gdal\n",
    "from helpers import *\n",
    "from imputation import Imputation as imp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fe9f5b-231e-48c2-a6a6-54e93ec01188",
   "metadata": {},
   "source": [
    "### Step 2 : The code below takes the input file(raster image) and runs imputation algorithms on the raster image and stores them in the specified output folder\n",
    "\n",
    "#### Explanation of the flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff655e52-a3dc-4b02-be14-4016f94bd29f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#### Initialization \n",
    "# - Get input folder \n",
    "# - read each image in the folder using gdal as numpy array (Important : check the metadata of file and specify scale factor)\n",
    "# - crop the image to have equal width and height so that the algorithms converge. \n",
    "\n",
    "#### Creation of missing pixels \n",
    "# - for each image create missing pixels (percentage of missing pixels - specified by the user if needed)\n",
    "# - creates a new folder if not exisiting and saves it in a separate folder in the specified output folder. \n",
    "\n",
    "#### Predict missing pixels \n",
    "# - Set the parameters such as hil and iterations \n",
    "# - \n",
    "#   for each algorithm\\\n",
    "#         for each image\\\n",
    "#           run imputation\\ \n",
    "#           create tiff file using CreateGeotiff function\\ \n",
    "#           create a folder with algorithm name if not existing and save it in the folder\n",
    "#### Create Geotiff \n",
    "# - creates geotiff from the input raster array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe15dd2b-9fa1-4bc6-ba6d-f22a8316be65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import traceback\n",
    "from pathlib import Path\n",
    "from osgeo import gdal\n",
    "from imputation import Imputation as imp  \n",
    "\n",
    "class Imputation:\n",
    "    def __init__(self, inputFile, scaleFactor=0.00002, outputFile=None):\n",
    "        \"\"\"\n",
    "        Initialize the Imputation class with input parameters\n",
    "        \n",
    "        :param inputFile (str): Path to the input image file.\n",
    "        :param scaleFactor (float, optional): Scaling factor for the image values. Default is 0.00002.\n",
    "        :param outputFile (str, optional): Path to the output directory. Default is None.\n",
    "     \n",
    "        \"\"\"\n",
    "        \n",
    "        self.inputFilePath = inputFile\n",
    "        self.outputFilePath = outputFile\n",
    "        self.scaleFactor = scaleFactor\n",
    "        self.imputedArrays = []\n",
    "        self.fileName = Path(self.inputFilePath).stem\n",
    "        self.percent = None\n",
    "        self.algos = ['siLRTC', 'haLRTC', 'CMTF', 'CMSI', 'cpALS', 'Base']\n",
    "        \n",
    "        try:\n",
    "            # Open input file using gdal and extract relevant information\n",
    "            self.data = gdal.Open(self.inputFilePath)\n",
    "            self.geoTrans = self.data.GetGeoTransform()\n",
    "            self.projection = self.data.GetProjection()\n",
    "            self.rasterArray = self.data.ReadAsArray().T * scaleFactor\n",
    "            self.imgWidth = self.rasterArray.shape[0]\n",
    "            self.imgHeight = self.rasterArray.shape[1]\n",
    "            \n",
    "            if self.imgHeight != self.imgWidth:\n",
    "                croppedShape = min(self.imgWidth, self.imgHeight)\n",
    "                self.rasterArray = self.rasterArray[:croppedShape, :croppedShape, :]\n",
    "            \n",
    "            # Initialize the 'imp' class with rasterArray\n",
    "            self.impute = imp(self.rasterArray)\n",
    "\n",
    "        except:\n",
    "            print(\"Unable to read input file using gdal\")\n",
    "            traceback.print_exc()\n",
    "\n",
    "    def createMissingPixels(self, percent=10, method='random'):\n",
    "        \n",
    "        \"\"\"\n",
    "        Create missing pixels in the image.\n",
    "\n",
    "        :param percent (int, optional): Percentage of missing pixels to create. Default is 10.\n",
    "        :param method (str, optional): Method for creating missing pixels. Default is 'random'.\n",
    "        \"\"\"\n",
    "        self.percent = percent\n",
    "        self.mask, self.corruptImage = self.impute.synthetic_mask((100 - self.percent) / 100)\n",
    "        path = str(self.outputFilePath + '/' + str(self.fileName))\n",
    "        checkFolder = os.path.isdir(path)\n",
    "        \n",
    "        if not checkFolder:\n",
    "            os.makedirs(path)\n",
    "            print('created Folder', path)\n",
    "        \n",
    "        # Create GeoTIFF file for corruptImage\n",
    "        self.CreateGeoTiff(outRaster=str(path + '/' + str(self.percent) + 'missingNew.tif'),\n",
    "                           data=self.corruptImage,\n",
    "                           geo_transform=self.geoTrans, projection=self.projection)\n",
    "\n",
    "    def predictMissingPixels(self, outputFolder, algo=None, tensorRank=12):\n",
    "        \n",
    "        \"\"\"\n",
    "        Predict missing pixels using specified algorithm or all algorithms.\n",
    "\n",
    " \n",
    "        :param outputFolder (str): Path to the output directory.\n",
    "        :param algo (str, optional): Algorithm to use for prediction. Default is None.\n",
    "        :param tensorRank (int, optional): Rank for tensor-based algorithms. Default is 12.\n",
    "        \"\"\"\n",
    "        if algo is None:\n",
    "            print(\"Running on all algorithms\")\n",
    "            self.results = {}\n",
    "            \n",
    "            if self.impute.get_corrupt_img() is None:\n",
    "                self.impute.generate_mask(approximate_mask=True)\n",
    "                print(\"Generating Approximate Mask\")\n",
    "            \n",
    "            # Perform imputation and record runtime\n",
    "            self.imputedArrays, self.algoRuntime = self.impute.impute(speed=\"slow\", hil=0, skip_vis=0)\n",
    "            \n",
    "            self.evalResults = []\n",
    "            self.runTime = []\n",
    "            \n",
    "            for i in range(len(self.algos) - 1):\n",
    "                path = str(outputFolder + self.algos[i] + '/' + str(filename))\n",
    "                checkFolder = os.path.isdir(path)\n",
    "                \n",
    "                if not checkFolder:\n",
    "                    os.makedirs(path)\n",
    "                    print('created Folder', path)\n",
    "                \n",
    "                # Create GeoTIFF files for imputed images and calculate RSE\n",
    "                self.CreateGeoTiff(outRaster=str(path + '/' + str(self.percent) + self.algos[i] + 'New.tif'),\n",
    "                                   data=self.imputedArrays[i],\n",
    "                                   geo_transform=self.geoTrans, projection=self.projection)\n",
    "                self.evalResults.append(RSE(self.rasterArray, self.imputedArrays[i]))\n",
    "                self.runTime.append(self.algoRuntime[i + 1] - self.algoRuntime[i])\n",
    "            \n",
    "            self.runTime.append(None)\n",
    "            self.evalResults.append(RSE(self.rasterArray, self.corruptImage))\n",
    "            \n",
    "            # Store evaluation results and runtime information\n",
    "            self.results = {'fileName': [self.fileName] * len(self.algos),\n",
    "                             'missingPercent': [str(self.percent)] * len(self.algos),\n",
    "                             'algo': self.algos, 'RSE': self.evalResults, 'runTime': self.runTime}\n",
    "            # print(self.tempDict)\n",
    "            return self.results\n",
    "        \n",
    "        def CreateGeoTiff(self, outRaster, data, geo_transform, projection):\n",
    "            \"\"\"\n",
    "            Create a GeoTIFF file from the provided data.\n",
    "\n",
    "            Parameters:\n",
    "                outRaster (str): Output path for the GeoTIFF file.\n",
    "                data (numpy.ndarray): Image data to be written as a GeoTIFF.\n",
    "                geo_transform (tuple): Geotransform information.\n",
    "                projection (str): Projection information.\n",
    "            \"\"\"\n",
    "            data = data.T\n",
    "            driver = gdal.GetDriverByName('ENVI')\n",
    "\n",
    "            no_bands, rows, cols = data.shape\n",
    "            DataSet = driver.Create(outRaster, cols, rows, no_bands, gdal.GDT_Float32)\n",
    "            DataSet.SetGeoTransform(geo_transform)\n",
    "            DataSet.SetProjection(projection)\n",
    "\n",
    "            for i, image in enumerate(data, 1):\n",
    "                DataSet.GetRasterBand(i).WriteArray(image)\n",
    "\n",
    "            DataSet.FlushCache()\n",
    "            DataSet = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f043a1-d945-40fb-b0fb-c458776d1bcb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 3 :  The below code is to conduct experiments on each dataset \n",
    "\n",
    "- for each file in the input folder \n",
    "      for each missing percent(from 10% to 50%)\n",
    "         create missing pixels \n",
    "         call imputation class function to predict missing pixels \n",
    "         get the results and store the statistics in a dataframe for further analysis \n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42116c8-1315-457f-94fe-e14ad501f181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create an empty DataFrame to store results\n",
    "finalDataframe = pd.DataFrame(columns=['fileName', 'missingPercent', 'algo', 'RSE', 'runTime'])\n",
    "\n",
    "# Loop through files in the specified path\n",
    "for filename in os.listdir(path):\n",
    "    if filename.endswith('.IMG'):\n",
    "        print(filename)\n",
    "        \n",
    "        # Iterate over missing percentage values (10 to 50, step 10)\n",
    "        for missingPercent in range(10, 60, 10):\n",
    "            filePath = os.path.join(path, filename)\n",
    "            \n",
    "            # Create an instance of the Imputation class\n",
    "            impute = Imputation(inputFile=filePath, outputFile=path)\n",
    "            \n",
    "            # Create missing pixels in the image\n",
    "            impute.createMissingPixels(percent=missingPercent)\n",
    "            \n",
    "            # Predict missing pixels using the specified algorithms\n",
    "            results = impute.predictMissingPixels(outputFolder=path)\n",
    "            \n",
    "            # Concatenate the results DataFrame with the new results\n",
    "            finalDataframe = pd.concat([finalDataframe, pd.DataFrame(results)], ignore_index=True)\n",
    "        \n",
    "        # print('------------------1file---------------------')\n",
    "\n",
    "# Save the final results DataFrame to a TSV file\n",
    "finalDataframe.to_csv('imputation_ChandDataset2_Results.tsv', sep='\\t')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2f4ac2-f003-487a-a018-1085d6955ded",
   "metadata": {},
   "source": [
    "### Step 4 : Creating heat map for the above obtained results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c0f11a-867e-426d-9fcb-e80eb48cd9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "from osgeo import gdal\n",
    "\n",
    "\n",
    "\n",
    "# function to calculate RMSE values of each pixel in the image\n",
    "def calculate_rmse(image1, image2):\n",
    "    mse = np.mean((image1 - image2) ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "\n",
    "# Filepath of images \n",
    "orig_image = '/Users/bunny/PycharmProjects/Imputation/data_/MI/dataset2/Area2_MI_MAP_03_N22E196N21E197SC.tif'\n",
    "predicted_image = '/Users/bunny/PycharmProjects/Imputation/data_/MI/dataset2/CMSI/Area2_MI_MAP_03_N22E196N21E197SC.tif/10CMSI.tif'\n",
    "\n",
    "\n",
    "# read images using gdal and scale factor of the file \n",
    "#(The data is read as (9,1048,1048) i.e, color bands,width, height) using the gdal library in order to visualize the image using matplotlib I have transformed the image \n",
    "predicted_image = gdal.Open(predicted_image).ReadAsArray().T\n",
    "original_image = gdal.Open(orig_image).ReadAsArray().T * 0.00002\n",
    "original_image = original_image[:403,:403,:]\n",
    "\n",
    "\n",
    "# Read it as numpy array \n",
    "original_array = np.array(original_image)\n",
    "predicted_array = np.array(predicted_image)\n",
    "\n",
    "# call the rmse function with the inputs \n",
    "rmse_array = np.sqrt(np.mean((original_array - predicted_array) ** 2, axis=-1))\n",
    "\n",
    "# Create heat map\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(original_array[:, :, :3])\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(predicted_array[:, :, :3])\n",
    "plt.title('Predicted Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(rmse_array, cmap='hot', interpolation='nearest')\n",
    "plt.colorbar(label='RMSE Value')\n",
    "plt.title('RMSE Heatmap')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
